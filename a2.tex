\documentclass{article}
\usepackage{graphicx} % For figures
\usepackage{float} % For figure positioning
\usepackage{subcaption} % For side-by-side figures
\usepackage{amsmath} % For math environments align, aligned, gather, gathered, multline

\begin{document}
    \raggedright
    \title{STAT380: Assignment 2  \\}
    \author{Vivienne Crowe ID:40071153}
    \date{4/2/21}
    
    \maketitle

    \section{}
    \subsection{}

    A.5 

    First note that for ordinary least squares:

    \[\hat{\beta} = (\bf{X}^T\bf{X})^{-1}\bf{X}\bf{y}\]

    Since $\bf{X}$ is square and full rank, it is therefore inveritiable, and so 
    $(\bf{X}^T\bf{X})^{-1} = \bf{X}^{-1} (\bf{X}^{T})^{-1}$. So it follows that:
    \[\hat{\beta} = \bf{X}^{-1}\]

    Now I'll show that $\bf{X}^{-1} = V \Sigma ^{-1}U^T$.

    \[
        \begin{aligned}
            \bf{X(V \Sigma ^{-1}U^T)} & = \bf{(V \Sigma ^{-1}U^T)}(U \Sigma V^T)\\
            & =  \bf{(V \Sigma ^{-1}}\Sigma V^T)\\
            & =  \bf{(VV^T)}\\
            & =  \bf{I}\\
        \end{aligned}
    \]

    Now onto the solution for ridge regression, the problem statement, in vector notation is:

    \[
        \begin{aligned}
            \min_\beta \quad & (\bf{y-X\beta)^T(y-X\beta}) - \lambda \beta^T\beta \\
           \min_\beta \quad & \bf{y^Ty-2y^TX\beta + \beta^T X^T X\beta}) - \lambda \beta^T\beta
        \end{aligned}
    \]
    
    Now to solve for where the derivative is equal to zero.

    \[
        \begin{aligned}
            0 & =  \frac{\partial}{\partial \beta} \bf{y^Ty-2y^TX\beta + \beta^T X^T X\beta} - \lambda \beta^T\beta \\
            0 & =  -2\bf{y^TX + (X^T X + X^T X) \beta} - 2\lambda \beta \\
            \bf{y^TX} & = \bf{(X^T X + \lambda I)\beta} \\
            \implies \hat{\beta} & = \bf{(X^T X + \lambda I)^{-1}y^TX}
        \end{aligned}
    \]

    

\end{document}